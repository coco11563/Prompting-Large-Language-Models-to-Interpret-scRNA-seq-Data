{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, disable_caching\n",
    "disable_caching()\n",
    "DATASET_DIR = \"./data/human_1k_demo\"\n",
    "demo_dataset = load_from_disk(DATASET_DIR)\n",
    "\n",
    "celltype_map_dict_dir = os.path.join(DATASET_DIR, \"name_id_dict.json\")\n",
    "with open(celltype_map_dict_dir) as file:\n",
    "    celltype_map = json.load(file)\n",
    "celltype_map = {v:k for k,v in celltype_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "PRETRAINED_LLM_PATH = \"\"\n",
    "\n",
    "model = netscInterpreter(\n",
    "    llm=\"llama\",\n",
    "    pretrained_llm=PRETRAINED_LLM_PATH,\n",
    "    num_classes=1000,\n",
    "    init_range=0.02)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f\"model has {total_params / 1e6} Million params\")\n",
    "print(f\"model has {total_params} params\\n\")\n",
    "print(f\"model has {trainable_params} trainable params\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "per_gpu_batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "epochs = 8\n",
    "warmup_steps = 1000\n",
    "\n",
    "gpu_ids = [1,2]\n",
    "num_gpus = len(gpu_ids)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \",\".join(map(str, gpu_ids))\n",
    "\n",
    "splited_dataset = demo_dataset.train_test_split(train_size=0.9, test_size=0.1, seed=0)\n",
    "\n",
    "fit_dataset = {\"train\": Dataset(splited_dataset[\"train\"], dtype=dtype, seed=0),\n",
    "               \"test\": Dataset(splited_dataset[\"test\"], dtype=dtype, seed=0)}\n",
    "\n",
    "if num_gpus>1:\n",
    "    import torch.multiprocessing as mp\n",
    "    from functools import partial\n",
    "    os.environ['MASTER_ADDR'] = '127.0.1.1'\n",
    "    os.environ['MASTER_PORT'] = '8848'\n",
    "    fit_func = partial(model.fit, epochs=epochs, num_workers=4, num_gpus=num_gpus, lr=lr, batch_size=per_gpu_batch_size, gradient_accumulation_steps=gradient_accumulation_steps, warmup_steps=warmup_steps, log_wandb=True, display_metrics=[\"accuracy\", \"f1\"])\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "    manager = mp.Manager()\n",
    "    results = manager.dict()\n",
    "    try:\n",
    "        mp.spawn(fit_func, args=(fit_dataset, results,), nprocs=num_gpus, join=True)\n",
    "        model: netscInterpreter = results[0][\"model\"]\n",
    "    except KeyboardInterrupt as e:\n",
    "        for proc in mp.active_children():\n",
    "            proc.terminate()\n",
    "else:\n",
    "    results = model.fit(0, fit_dataset, None, epochs=epochs, num_workers=4, num_gpus=num_gpus, lr=lr, batch_size=per_gpu_batch_size, gradient_accumulation_steps=gradient_accumulation_steps, warnup_steps=warmup_steps, log_wandb=True, display_metrics=[\"accuracy\", \"f1\"])\n",
    "    model: netscInterpreter = results[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.val(\n",
    "        fit_dataset[\"test\"],\n",
    "        celltype_map,\n",
    "        device=\"cuda:0\",\n",
    "        model=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_umap()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "X",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
